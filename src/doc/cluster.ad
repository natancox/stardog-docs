= High Availability Cluster

In this section we explain how to configure, use, and administer Stardog Cluster
for uninterrupted operations. Stardog Cluster is a collection of Stardog Server
instances running on one or more virtual or physical machines that, *from the
client's perspective*, behave like a single Stardog Server instance. To fully
achieve this effect requires DNS (i.e., with `SRV` records) and proxy
configuration that's left as an exercise for the user. Of course Stardog Cluster
should have some different operational properties, the main one of which is high
availability. But from the client's perspective Stardog Cluster should be
indistinguishable from non-clustered Stardog.footnote:["Client" here means the
client of Stardog APIs.]

NOTE: High Availability requires *at least* three Stardog and three ZooKeeper
nodes in the Cluster. ZooKeeper works best, with respect to fault resiliency,
with an ensemble size that is an odd-number greater than or equal to three: 3,
5, 7, etc.footnote:["Because ZooKeeper requires a majority, it is best to use an
odd number of machines. For example, with four machines ZooKeeper can only
handle the failure of a single machine; if two machines fail, the remaining two
machines do not constitute a majority. However, with five machines ZooKeeper can
handle the failure of two machines." See
https://zookeeper.apache.org/doc/r3.1.2/zookeeperAdmin.html[Zk Admin] for more.]
With respect to performance, larger cluster sizes (Stardog and ZooKeeper)
perform better than smaller ones for reads, while larger cluster sizes perform
worse for writes. It is responsibility of the administrator to find the right
balance.

== Cluster Guarantees

Stardog Cluster implements an atomic commitment protocol based on
http://en.wikipedia.org/wiki/Two-phase_commit_protocol[two-phase commit (2PC)]
over a shared replicated memory that's provided by Apache ZooKeeper. A cluster
is composed of a set of Stardog servers and a ZooKeeper ensemble running
together. One of the Stardog servers is the Coordinator and the others are
Participants.

In case the Coordinator fails at any point, a new Coordinator will be elected
out of the remaining available Participants. Stardog Cluster supports both
`read` (e.g., querying) and `write` (e.g., adding data) requests. Read requests
are served by the Stardog node receiving it, whereas write requests are
transparently forwarded to and handled by the Coordinator. In some future
release we may change the protocol implemented by the Cluster and thus change
some of the allowable topologies, including multiple-writers and
multiple-readers.

When a client commits a transaction (containing a list of `write` requests), it
will be acknowledged by the Coordinator only **after every non-failing Participant
has committed the transaction**. If a Participant fails during the process of
committing a transaction, it will be expelled from the cluster by the
Coordinator and put in a temporary `failed` state.

If the Coordinator fails during the process, the transaction will be aborted,
and a new Coordinator will be elected automatically. Since `failed` nodes are
not used for any subsequent `read` or `write` requests, **if a commit is
acknowledged by the Coordinator, then Stardog Cluster guarantees that the data
has been accordingly modified at *every* available node in the cluster**.

While this approach is less performant with respect to write
operations than eventual consistency used by other distributed databases,
typically those databases offer a much less expressive data model than Stardog,
which makes an eventually consistency model more appropriate for those systems.
But since Stardog's data model is not only richly expressive but rests in part
on provably correct semantics, we think that a strong consistency model is worth
the cost.footnote:[Based on customer feedback we may relax these consistency
guarantees in some future release. Please get in touch if you think an
eventually consistent approach is more appropriate for your use of Stardog.]

== Single Server Migration

It is assumed that Stardog nodes in a Stardog Cluster are always going to be
used within a cluster context. Therefore, if you want to migrate from a Stardog
instance running in single server mode to running in a cluster, it is advised
that you create backups of your current databases and then import them to the
cluster in order to be able to provide the guarantees explained above. If you
simply add a Stardog instance to cluster that was previously running in single
server mode, _it will sync to the state of the cluster_; local data could be
removed when syncing with the cluster state.

== Configuration

To deploy Stardog Cluster you use `stardog-admin` commands and some
additional configuration. Stardog Cluster depends on Apache
ZooKeeper.

In Stardog 3.0 we added `stardog-admin cluster generate` to bootstrap
a cluster configuration and, thus, to ease installation. You may be
able to get away with simply passing a list of hostnames or IP
addresses for the cluster's nodes.

[source,bash]
----
$ stardog-admin cluster generate --output-dir /home/stardog 10.0.0.1 10.0.0.2 10.0.0.3
----

See the link:/man/cluster-generate.html[man page] for the details.

In the following installation notes, we install Stardog Cluster in a
pseudo-distributed 3-node configuration, that is, Stardog and ZooKeeper nodes
are colocated in the same machine. In a production environment we strongly recommend
that each ZooKeeper process runs in a different machine and, if possible, that
ZooKeeper has a separate drive for its data directory. If you need a larger
cluster, adjust accordingly.footnote:[In order to deploy a cluster to a single
machine--for example, for testing or development--you must ensure that
each Stardog and ZooKeeper servers has a different home location.]

. <<Quick Start Guide,Install>> Stardog {version} on each machine in the cluster.
+
NOTE: The smart thing to do here, of course, is to use whatever infrastructure
you have in place to automate software installation. Adapting Stardog
installation to Chef, Puppet, cfengine, etc. is left as an exercise for the
reader.
+
. Make sure a valid Stardog license key (whether Developer, Enterprise, or a
30-day eval key) for the size of cluster you're creating exists and resides in
`STARDOG_HOME` on each node. You must also have a `stardog.properties` file with the following
information **for each node in the cluster**:
+
[source,bash]
----
# Flag to enable the cluster, without this flag set, the rest of the properties have no effect
pack.enabled=true
# this node's IP address (or hostname) where other Stardog nodes are going to connect
pack.node.address=196.69.68.1
# the connection string for ZooKeeper where cluster state is stored
pack.zookeeper.address=196.69.68.1:2180,196.69.68.2:2180,196.69.68.3:2180
# credentials used for securing ZooKeeper state
pack.cluster.username=pack
pack.cluster.password=admin
----
+
`pack.zookeeper.address` is a ZooKeeper connection string where cluster stores its
state. `pack.cluster.username` and `pack.cluster.password` are user and password
tokens for ZooKeeper cluster communications and may be different from actual Stardog users
and passwords; however, **all nodes must use the same user and password
combination.** `pack.node.address` is not a required property.  The local address of the node, by default,
is `InetAddress.getLocalhost().getAddress()`, which should work for many deployments.  However if you're
using an atypical network topology and the default value is not correct, you can provide a value for this
property.
+
. Create the ZooKeeper configuration for each node. This config file is just a standard ZooKeeper configuration file. The following
config file should be sufficient for most cases.
+
On node 1:
+
[source,bash]
----
tickTime=2000
# Make sure this directory exists and
# ZK can write and read to and from it.
dataDir=/data/zookeeperdata/
clientPort=2180
initLimit=5
syncLimit=2
# This is an enumeration of all nodes in
# the cluster and must be identical in
# each node's config.
server.1=196.69.68.1:2888:3888
server.2=196.69.68.2:2888:3888
server.3=196.69.68.3:2888:3888
----
+
On node 2:
+
[source,bash]
----
tickTime=2000
dataDir=/data/zookeeperdata/
clientPort=2180
initLimit=5
syncLimit=2
server.1=196.69.68.1:2888:3888
server.2=196.69.68.2:2888:3888
server.3=196.69.68.3:2888:3888
----
+
Finally, on node 3:
+
[source,bash]
----
tickTime=2000
dataDir=/data/zookeeperdata/
clientPort=2180
initLimit=5
syncLimit=2
server.1=196.69.68.1:2888:3888
server.2=196.69.68.2:2888:3888
server.3=196.69.68.3:2888:3888
----
+
NOTE: The `clientPort` specified in `zookeeper.properties` and the ports used in `pack.cluster.address` in
`stardog.properties` must be the same.
+
. `dataDir` is where ZooKeeper persists cluster state and where it
writes log information about the cluster.
+
[source,bash]
----
$ mkdir /data/zookeeperdata # on node 1
$ mkdir /data/zookeeperdata # on node 2
$ mkdir /data/zookeeperdata # on node 3
----
+
. ZooKeeper requires a `myid` file in the `dataDir` folder to identify itself, you will create that file as follows
for `node1` and `node2`, respectively:
+
[source,bash]
----
$ echo 1 > /data/zookeeperdata/myid # on node 1
$ echo 2 > /data/zookeeperdata/myid # on node 2
$ echo 3 > /data/zookeeperdata/myid # on node 3
----

== Installation

In the next few steps you will use the Stardog Admin CLI commands to deploy
Stardog Cluster: that is, ZooKeeper and Stardog itself. We'll also configure
HAProxyfootnote:[There's nothing special about HAProxy here; you could implement
this proxy functionality in many different ways. We use HAProxy because it's
relatively easy and ubiquitous. YMMV.] as an example of how to use of Stardog
Cluster behind a proxy for load-balancing and fail-over capability.

NOTE: As mentioned earlier, we recommend to have Stardog and ZooKeeper nodes in
different machines, but for the purpose of this example we'll colocate them in
the same machines.

. *Start ZooKeeper with the `stardog-admin cluster zkstart` subcommand*
+
[source,bash]
----
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 1
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 2
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 3
----
+
Which uses the `zookeeper.properties` config file in `~/stardog` and log its
output to `~/stardog/zookeeper.log`. If your `$STARDOG_HOME` is set to `~/stardog`,
then you don't need to specify the `--home` option. For more info about the command:
+
[source,bash]
----
$ ./stardog-admin help cluster zkstart
----
+
Once ZooKeeper is started, you can start Stardog Cluster:
+
[source,bash]
----
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 1
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 2
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 3
----
+
Again, if your `$STARDOG_HOME` is set to `~/stardog`, you don't need to specify
the `--home` option.
+
NOTE: Make sure to allocate roughly twice as much heap for Stardog than you would normally
do for single-server operation since there can be an additional overhead involved for
replication in the cluster. Also, we start Stardog here on the non-default port
(`5821`) so that you can use a proxy or load-balancer in the same machine which can
run on the default port (`5820`), meaning that Stardog clients can act normally (i.e.,
use the default port, `5820`) since they need to interact with HAProxy.
+
. *Start HAProxy*
+
In most Unix-like systems, HAProxy is available via package managers, e.g. in Debian-based systems:
+
[source,bash]
----
$ sudo apt-get update
$ sudo apt-get install haproxy
----
+
At the time of this writing, this will install HAProxy 1.4. You can refer to the
http://www.haproxy.org/[official site] to install a later release.
+
Place the following configuration in a file (such as `haproxy.cfg`) in order to
point HAProxy to the Stardog Cluster.
+
[source,text]
----
global
    daemon
    maxconn 256

defaults
    timeout connect 5s
    timeout client 1h
    timeout server 1h

# where HAProxy will listen for connections
frontend stardog-in
    option tcpka # keep-alive
    bind *:5820
    default_backend stardogs

# the Stardog servers - we use sticky sessions
backend stardogs
    option tcpka # keep-alive
    # sticks the client to a given server for the duration of the connection
    #   using the destination IP address
    stick-table type integer size 200k expire 30m
    stick on dst
    # these three lines perform a health check
    # they will check that the node accepts connections and
    # that it's operational within the cluster
    option tcp-check
    tcp-check send-binary 50494e47 # PING
    tcp-check expect binary 504F4e47 # PONG
    # replace these IP addresses with the corresponding node address
    server stardog1 196.69.68.1:5821 maxconn 32 check
    server stardog2 196.69.68.2:5821 maxconn 32 check
    server stardog3 196.69.68.3:5821 maxconn 32 check
----
+
Conversely, if you wish to operate the cluster in HTTP-only mode, you can
use the following HAProxy configuration:
+
[source,text]
----
global
    daemon
    maxconn 256

defaults
    timeout connect 5s
    timeout client 1h
    timeout server 1h

frontend stardog-in
    option tcpka # keep-alive
    bind *:5820
    default_backend stardogs

backend stardogs
    mode http
    # this line serves the same purpose as PING/PONG in tcp mode
    option httpchk GET /admin/healthcheck
    # replace these IP addresses with the corresponding node address
    server stardog1 196.69.68.1:5821 maxconn 32 check
    server stardog2 196.69.68.2:5821 maxconn 32 check
    server stardog3 196.69.68.3:5821 maxconn 32 check
----
+
Finally,
+
[source,bash]
----
$ haproxy -f haproxy.cfg
----
+
For more info on configuring HAProxy please refer to the http://www.haproxy.org/#docs[official
documentation]. In production environments we recommend running multiple proxies
to avoid single point of failures, and use DNS solutions for fail-over.
+
Now Stardog Cluster is running on 3 nodes, one each on 3 machines. Since
HAProxy was conveniently configured to use port `5820` you can execute
standard Stardog CLI commands to the Cluster:
+
[source,bash]
----
$ ./stardog-admin db create -n myDb
$ ./stardog data add myDb /path/to/my/data
$ ./stardog query myDb "select * { ?s ?p ?o } limit 5"
----
+
In order to shut down the cluster you only need to execute the following command once:
+
[source,bash]
----
$ ./stardog-admin server stop
----
+
You still need to shut down ZooKeeper independently.

.Running Stardog Cluster on a Single Machine
****
For testing, development, or other purposes it may be advantageous to run
Stardog Cluster on a single machine. Of course this won't provide much actual
high availability, but it may be a reasonable choice in some cases.

The following changes must be made to the multi-machine configuration and
installation described previously:

[horizontal]
Stardog configuration::

* different `STARDOG_HOME` for each node
* different Stardog port for each node
** the easiest setup is if no Stardog listens on port `5820`
* at least one (but no more than one) proxy on port `5820`
* different Watchdog port for each node via `watchdog.port` in `stardog.properties`

ZooKeeper configuration::

* different, that is, non-overlapping port ranges for each node
* different data directory for each node (e.g., different subdirectories in `/data/zookeeperdata`)

****

== Cluster Topologies & Cluster Size

In the configuration instructions above, we assume a particular Cluster
topology, which is to say, for each node `n` of a cluster, we run Stardog,
ZooKeeper, and HAProxy. But this is not the only topology supported by Stardog
Cluster. ZooKeeper nodes run independently, so other topologies--three ZooKeeper
servers and five Stardog servers are possible--you just have to point Stardog to
the corresponding ZooKeeper ensemble.

To add more Stardog Cluster nodes, simply repeat the steps for Stardog on
additional machines. Generally, as mentioned above, Stardog Cluster size should
be an odd number greater or equal to 3.

WARNING: ZooKeeper uses a very write heavy protocol; having Stardog and ZooKeeper
both writing to the *same* disk can yield contention issues, resulting in
timeouts at scale. We recommend at a minimum having the two services writing to
separate disks to reduce contention or, ideally, have them run on separate nodes
entirely.

== Stardog Cluster Client

To use Stardog Cluster with standard Stardog clients and CLI tools in the
ordinary way--`stardog-admin` and `stardog`--you must have Stardog installed
locally. With the provided Stardog binaries in the Stardog Cluster distribution
you can query the state of Cluster:footnote:[In 3.x we will integrate Netflix's
Exhibitor for Stardog Cluster management. Ping us if this is a priority for
you.]

[source,bash]
----
$ ./stardog-admin --server snarl://<ipaddress>:5820/ cluster info
----

where `ipaddress` is the IP address of any of the nodes in the cluster. This
will print the available nodes in the cluster, as well as the roles (participant
or coordinator). You can also input the proxy IP address and port to get the
same information.

To add or remove data, issue `stardog data add` or `remove` commands to
any node in the cluster. Queries can be issued to any node in the cluster using
the `stardog query` command. All the `stardog-admin` features are also available
in Cluster, which means you can use any of the commands to create
databases, administer users, and the rest of the functionality.
